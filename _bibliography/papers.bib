@INPROCEEDINGS{teapot,
  title={Teapot: Efficiently Uncovering Spectre Gadgets in COTS Binaries},
  author={Lin, Fangzheng and Wang, Zhongfa and Sasaki, Hiroshi},
  code={https://github.com/titech-caras/teapot},
  arxiv={2411.11624},
  booktitle={ACM/IEEE International Symposium on Code Generation and Optimization (CGO)}, 
  year={2025},
  abstract={Speculative execution is crucial in enhancing modern processor performance but can introduce Spectre-type vulnerabilities that may leak sensitive information. Detecting Spectre gadgets from programs has been a research focus to enhance the analysis and understanding of Spectre attacks. However, one of the problems of existing approaches is that they rely on the presence of source code (or are impractical in terms of run-time performance and gadget detection ability). This paper presents Teapot, the first Spectre gadget scanner that works on COTS binaries with comparable performance to compiler-based alternatives. As its core principle, we introduce Speculation Shadows, a novel approach that separates the binary code for normal execution and speculation simulation in order to improve run-time efficiency. Teapot is based on static binary rewriting. It instruments the program to simulate the effects of speculative execution and also adds integrity checks to detect Spectre gadgets at run time. By leveraging fuzzing, Teapot succeeds in efficiently detecting Spectre gadgets. Evaluations show that Teapot outperforms both performance (more than 20x performant) and gadget detection ability than a previously proposed binary-based approach.},
  selected={true},
}

@inproceedings{IFRVP,
  title={Real-Time Video Prediction with Fast Video Interpolation Model and Prediction Training},
  author={Hirose, Shota and Kotoyori, Kazuki and Arunruangsirilert, Kasidis and Lin, Fangzheng and Sun, Heming and Katto, Jiro},
  booktitle={IEEE International Conference on Image Processing (ICIP)}, 
  year={2024},
  organization={IEEE}
}

@inproceedings{vcip2023,
  title={PTS-LIC: Pruning Threshold Searching for Lightweight Learned Image Compression},
  author={Luo, Ao and Sun, Heming and Liu, Jinming and Lin, Fangzheng and Katto, Jiro},
  booktitle={IEEE International Conference on Visual Communications and Image Processing (VCIP)},
  year={2023},
  organization={IEEE}
}

@INPROCEEDINGS{recoil,
  title={Recoil: Parallel rANS Decoding with Decoder-Adaptive Scalability},
  author={Lin, Fangzheng and Arunruangsirilert, Kasidis and Sun, Heming and Katto, Jiro},
  code={https://github.com/lin-toto/recoil},
  arxiv={2306.12141},
  booktitle={International Conference on Parallel Processing (ICPP)}, 
  year={2023},
  abstract={Entropy coding is essential to data compression, image and video coding, etc. The Range variant of Asymmetric Numeral Systems (rANS) is a modern entropy coder, featuring superior speed and compression rate. As rANS is not designed for parallel execution, the conventional approach to parallel rANS partitions the input symbol sequence and encodes partitions with independent codecs, and more partitions bring extra overhead. This approach is found in state-of-the-art implementations such as DietGPU. It is unsuitable for content-delivery applications, as the parallelism is wasted if the decoder cannot decode all the partitions in parallel, but all the overhead is still transferred. To solve this, we propose Recoil, a parallel rANS decoding approach with decoder-adaptive scalability. We discover that a single rANS-encoded bitstream can be decoded from any arbitrary position if the intermediate states are known. After renormalization, these states also have a smaller upper bound, which can be stored efficiently. We then split the encoded bitstream using a heuristic to evenly distribute the workload, and store the intermediate states and corresponding symbol indices as metadata. The splits can then be combined simply by eliminating extra metadata entries. The main contribution of Recoil is reducing unnecessary data transfer by adaptively scaling parallelism overhead to match the decoder capability. The experiments show that Recoil decoding throughput is comparable to the conventional approach, scaling massively on CPUs and GPUs and greatly outperforming various other ANS-based codecs.},
  selected={true}
}

@INPROCEEDINGS{lic-multistage,
  author={Lin, Fangzheng and Sun, Heming and Liu, Jinming and Katto, Jiro},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multistage Spatial Context Models for Learned Image Compression}, 
  year={2023},
  abstract={Recent state-of-the-art Learned Image Compression methods feature spatial context models, achieving great rate-distortion improvements over hyperprior methods. However, the autoregressive context model requires serial decoding, limiting runtime performance. The Checkerboard context model allows parallel decoding at a cost of reduced RD performance. We present a series of multistage spatial context models allowing both fast decoding and better RD performance. We split the latent space into square patches and decode serially within each patch while different patches are decoded in parallel. The proposed method features a comparable decoding speed to Checkerboard while reaching the RD performance of Autoregressive and even also outperforming Autoregressive. Inside each patch, the decoding order must be carefully decided as a bad order negatively impacts performance; therefore, we also propose a decoding order optimization algorithm.},
  volume={},
  number={},
  code={https://github.com/lin-toto/lic-multistage-spatial-context},
  arxiv={2302.09263},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10095875},
  selected={true}}

@inproceedings{flic,
  title={F-LIC: FPGA-based Learned Image Compression with a Fine-grained Pipeline},
  author={Sun, Heming and Yi, Qingyang and Lin, Fangzheng and Yu, Lu and Katto, Jiro and Fujita, Masahiro},
  booktitle={IEEE Asian Solid-State Circuits Conference (A-SSCC)},
  pages={1--3},
  year={2022},
  organization={IEEE}
}

@inproceedings{vcip2022,
  title={Real-time Learned Image Codec on FPGA},
  author={Sun, Heming and Yi, Qingyang and Lin, Fangzheng and Yu, Lu and Katto, Jiro and Fujita, Masahiro},
  booktitle={IEEE International Conference on Visual Communications and Image Processing (VCIP)},
  pages={1--1},
  year={2022},
  organization={IEEE}
}

@INPROCEEDINGS{licoris,
  author={Lin, Fangzheng and Sun, Heming and Katto, Jiro},
  booktitle={IEEE International Conference on Image Processing (ICIP)}, 
  title={Streaming-Capable High-Performance Architecture of Learned Image Compression Codecs}, 
  year={2022},
  abstract={Learned image compression allows achieving state-of-the-art accuracy and compression ratios, but their relatively slow runtime performance limits their usage. While previous attempts on optimizing learned image codecs focused more on the neural model and entropy coding, we present an alternative method to improving the runtime performance of various learned image compression models. We introduce multi-threaded pipelining and an optimized memory model to enable GPU and CPU workloads asynchronous execution, fully taking advantage of computational resources. Our architecture alone already produces excellent performance without any change to the neural model itself. We also demonstrate that combining our architecture with previous tweaks to the neural models can further improve runtime performance. We show that our implementations excel in throughput and latency compared to the baseline and demonstrate the performance of our implementations by creating a real-time video streaming encoder-decoder sample application, with the encoder running on an embedded device.},
  volume={},
  number={},
  code={https://github.com/lin-toto/licoris},
  arxiv={2208.01641},
  pages={286-290},
  doi={10.1109/ICIP46576.2022.9897695},
  selected={true}
  }
